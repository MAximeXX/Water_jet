# app.py â€” Waterjet Forecastï¼ˆä¸­æ–‡ç‰ˆï¼‰
# ------------------------------------------------
# - DB ç«¯ 1 åˆ†é’Ÿèšåˆï¼šé™ä½ä¼ è¾“é‡ã€åŠ é€Ÿ
# - ä¸¤ä¸ªé¢„æµ‹æ–¹æ³•ï¼šHolt(é˜»å°¼) + å†å²ç›¸ä¼¼æ®µ(Top-K)
# - ä¾§æ è¡¨å•ï¼šå¿…é¡»ç‚¹â€œå¼€å§‹é¢„æµ‹â€æ‰æ‰§è¡Œï¼›â€œæ¢å¤é»˜è®¤â€å¯ä¸€é”®æ¢å¤é»˜è®¤
# - æ–°å¢ï¼šé¡¶éƒ¨â€œåˆ·æ–°æœ€æ–°å€¼â€æŒ‰é’®ï¼Œå¯å®æ—¶æ›´æ–°â€œæœ€æ–°æ¸©åº¦/æ•…éšœç‡â€

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import requests

from datetime import datetime, time, timedelta, timezone
import pytz

# ============== åŸºç¡€é…ç½® ==============
API_URL      = "http://61.177.143.140:8086/query"
DB_NAME      = "DataDB"
MEASUREMENT  = "working_set"
READ_TIMEOUT = (10, 90)
SH_TZ        = pytz.timezone("Asia/Shanghai")
Z_FIXED      = 1.96                   # 95% ç½®ä¿¡åŒºé—´ç³»æ•°
MAX_PLOT_POINTS = 2500                # ç»˜å›¾é™é‡‡æ ·ä¸Šé™ï¼ˆä¸å½±å“é¢„æµ‹ï¼Œä»…å½±å“æ˜¾ç¤ºï¼‰

# ä¼ æ„Ÿå™¨æ˜ å°„ï¼šid -> å¯è¯»åç§°ï¼ˆå¯è‡ªè¡Œæ‰©å±•/æ›¿æ¢ï¼‰
SENSOR_MAP = {
    "wxa01sd01.calculate.sdjsd0011": "æ°´æ³µæ¸©åº¦ 1",
    "wxa01sd01.calculate.sdjsd0012": "æ°´æ³µæ¸©åº¦ 2",
}
LABEL_TO_ID = {v: k for k, v in SENSOR_MAP.items()}

# å¤ç”¨è¿æ¥
SESSION = requests.Session()

# ============== å·¥å…·å‡½æ•° ==============
def local_now():
    """è·å–ä¸Šæµ·æœ¬åœ°å½“å‰æ—¶é—´ï¼ˆå»ç§’ï¼‰ã€‚"""
    return datetime.now(SH_TZ).replace(second=0, microsecond=0)

def tz_to_plot(s: pd.Series) -> pd.Series:
    """æŠŠç´¢å¼•è½¬æˆä¸Šæµ·æ—¶åŒºä¸” naiveï¼ŒMatplotlib ç”»å›¾æ›´ç¨³ã€‚"""
    s = s.copy()
    if hasattr(s.index, "tz"):
        s.index = s.index.tz_convert(SH_TZ).tz_localize(None)
    return s

def downsample_for_plot(s: pd.Series, max_pts=MAX_PLOT_POINTS) -> pd.Series:
    """ç»˜å›¾ç”¨è½»åº¦ä¸‹é‡‡æ ·ï¼ˆä»…å½±å“å±•ç¤ºçš„æµç•…æ€§ï¼Œä¸å½±å“è¿ç®—ç²¾åº¦ï¼‰"""
    if s.empty or len(s) <= max_pts:
        return s
    step = max(1, len(s) // max_pts)
    return s.iloc[::step]

def fault_rate_from_temp(t: float) -> float:
    """
    æ•…éšœç‡è®¡ç®—ï¼š
      - è‹¥æ¸©åº¦ >= 45 â†’ 100%
      - è‹¥æ¸©åº¦ <= 25 â†’ 0%
      - ä»‹äºå…¶é—´æŒ‰çº¿æ€§æ¯”ä¾‹ï¼š(t - 25) / (45 - 25)
    è¿”å› 0.0~1.0
    """
    if t is None or pd.isna(t):
        return np.nan
    if t >= 45:
        return 1.0
    if t <= 25:
        return 0.0
    return max(0.0, min(1.0, (t - 25.0) / 20.0))

# ============== é»˜è®¤å‚æ•° ==============
def compute_defaults():
    """æ„é€ ä¸€å¥—â€œå½“å‰æ—¶é—´å‘å‰ 2 å°æ—¶â€çš„é»˜è®¤å‚æ•°"""
    now_sh   = local_now()
    start_sh = now_sh - timedelta(hours=2)
    return {
        "sensor_label": list(SENSOR_MAP.values())[0],
        "sel_date": now_sh.date(),
        "sh": start_sh.hour, "sm": start_sh.minute,   # start hour/minute
        "eh": now_sh.hour,   "em": now_sh.minute,     # end   hour/minute
        "steps": 30, "pat_len": 12, "top_k": 3, "roll_w": 7,
        "cache_buster": 0,   # ç”¨äºå¼ºåˆ¶åˆ·æ–°ç¼“å­˜
    }

# âœ… **å…³é”®ä¿®å¤**ï¼šåœ¨ä»»ä½• UI æ§ä»¶ä¹‹å‰ï¼Œç¡®ä¿ session_state å®Œæ•´åˆå§‹åŒ–
if "inited" not in st.session_state:
    st.session_state.update(compute_defaults())
    st.session_state["inited"] = True

def reset_to_defaults():
    st.session_state.update(compute_defaults())
    st.rerun()

def ss_get(key, default):
    """å®‰å…¨è¯»å– session_stateï¼ˆå…œåº•ï¼‰ã€‚"""
    return st.session_state[key] if key in st.session_state else default

# ============== DB ä¾§ 1 åˆ†é’ŸèšåˆæŠ“å– ==============
@st.cache_data(ttl=120)
def fetch_minutely_last(sensor_id: str, start_sh: datetime, end_sh: datetime, buster: int = 0) -> pd.Series:
    """
    InfluxQLï¼ˆå¯¹ 1.8 OSS å‹å¥½ï¼‰ï¼š
      - ç”¨ RFC3339 UTC æ—¶é—´æ–‡æœ¬ï¼ˆç¨³å®šï¼‰
      - åœ¨ DB ç«¯åš 1 åˆ†é’Ÿèšåˆï¼šlast(val)
      - å®¢æˆ·ç«¯å†è½¬å›ä¸Šæµ·æ—¶åŒº
      - buster ä»…ç”¨äºå‚ä¸ç¼“å­˜é”®ï¼Œå®ç°â€œå¼ºåˆ¶åˆ·æ–°â€
    """
    start_utc = start_sh.astimezone(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
    end_utc   = end_sh.astimezone(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")

    q = (
        f'SELECT last("val") AS v FROM "{MEASUREMENT}" '
        f"WHERE time >= '{start_utc}' AND time <= '{end_utc}' "
        f"AND \"id\" = '{sensor_id}' "
        f"GROUP BY time(1m) fill(none)"
    )
    # æŠŠ buster åŠ å…¥è¯·æ±‚å‚æ•°ï¼Œè¿›ä¸€æ­¥é¿å…ä»£ç†/ä¸­é—´å±‚å¤ç”¨ç¼“å­˜ï¼ˆéå¿…é¡»ï¼‰
    r = SESSION.get(API_URL, params={"db": DB_NAME, "q": q, "epoch": "ms", "_": buster}, timeout=READ_TIMEOUT)
    r.raise_for_status()
    payload = r.json()
    series = payload.get("results", [{}])[0].get("series", [])
    if not series:
        return pd.Series(dtype=float)

    s0 = series[0]
    df = pd.DataFrame(s0["values"], columns=s0["columns"])  # columns: time, v
    if df.empty or "time" not in df or "v" not in df:
        return pd.Series(dtype=float)

    df["time"] = pd.to_datetime(df["time"], unit="ms", utc=True).dt.tz_convert(SH_TZ)
    df = df.dropna(subset=["v"])
    s = df.set_index("time")["v"].astype(float).sort_index()

    # å¯¹é½å®Œæ•´åˆ†é’Ÿç´¢å¼•ï¼ˆç¼ºå¤±åˆ†é’Ÿä¿ç•™ NaNï¼‰
    full_idx = pd.date_range(start=start_sh, end=end_sh, freq="T", tz=SH_TZ)
    return s.reindex(full_idx)

# ============== é¢„æµ‹æ–¹æ³• ==============
def ci_from_sigma(center: pd.Series, sigma: float, hist_len: int, z: float = Z_FIXED):
    """åŸºäºæ®‹å·®æ ‡å‡†å·®çš„ç®€åŒ–ç½®ä¿¡åŒºé—´ï¼ˆæ­¥é•¿è¶Šè¿œç•¥æ”¾å®½ï¼‰ã€‚"""
    h = np.arange(1, len(center) + 1)
    widen = np.sqrt(1.0 + h / max(5, hist_len))
    return center - z * sigma * widen, center + z * sigma * widen

@st.cache_data(ttl=120, show_spinner=False)
def holt_damped(y: pd.Series, steps: int):
    """Holt é˜»å°¼è¶‹åŠ¿ï¼ˆstatsmodelsï¼›å¤±è´¥æ—¶å›é€€ä¸ºæŒä¹…åŒ–ï¼‰ã€‚"""
    y = y.dropna().sort_index()
    if y.empty or steps <= 0:
        return y.iloc[-0:0], y.iloc[-0:0], y.iloc[-0:0]
    try:
        from statsmodels.tsa.holtwinters import ExponentialSmoothing
        model = ExponentialSmoothing(y, trend="add", damped_trend=True, seasonal=None)
        fit = model.fit(optimized=True)
        pred = fit.forecast(steps)
        pred.index = pd.date_range(start=y.index[-1] + pd.Timedelta(minutes=1), periods=steps, freq="T")
        resid = (y - fit.fittedvalues.reindex(y.index)).dropna()
        sigma = float(resid.std(ddof=1)) if len(resid) > 3 else 0.0
        lo, up = ci_from_sigma(pred, sigma, len(y), Z_FIXED)
        return pred, lo, up
    except Exception:
        last = float(y.iloc[-1])
        idx = pd.date_range(start=y.index[-1] + pd.Timedelta(minutes=1), periods=steps, freq="T")
        base = pd.Series([last] * steps, index=idx)
        return base, base, base

@st.cache_data(ttl=120, show_spinner=False)
def pattern_match_fast(y: pd.Series, steps: int, pat_len: int = 12, k: int = 3):
    """çŸ¢é‡åŒ– Top-K å†å²ç›¸ä¼¼æ®µåŒ¹é…ï¼Œå½¢çŠ¶é…å‡†åé›†æˆã€‚"""
    y = y.dropna().sort_index()
    arr = y.values.astype(float)
    n = len(arr); need = pat_len + steps
    if steps <= 0 or n <= need:
        idx = pd.date_range(start=y.index[-1] + pd.Timedelta(minutes=1), periods=steps, freq="T")
        base = pd.Series([float(arr[-1])] * steps, index=idx)
        return base, base, base

    P = arr[-pat_len:]
    stride = arr.strides[0]
    m = n - need + 1
    windows = np.lib.stride_tricks.as_strided(arr, shape=(m, pat_len), strides=(stride, stride))

    win_mu = windows.mean(axis=1, keepdims=True)
    win_sd = windows.std(axis=1, keepdims=True); win_sd[win_sd == 0] = 1.0
    win_z  = (windows - win_mu) / win_sd
    Pz = (P - P.mean()) / (P.std() or 1.0)

    # è¿‘ä¼¼â€œç›¸å…³ç³»æ•°â€çš„ç›¸ä¼¼åº¦
    scores = (win_z * Pz).sum(axis=1) / pat_len
    k = max(1, min(k, m))
    top_idx = np.argpartition(-scores, kth=k-1)[:k]

    futures = []
    for sidx in top_idx:
        F = arr[sidx + pat_len : sidx + pat_len + steps]
        Fz = (F - F.mean()) / (F.std() or 1.0)
        F_adj = Fz * (P.std() or 1.0) + P.mean()
        F_adj += (P[-1] - F_adj[0])           # ä¸æœ€åä¸€ä¸ªè§‚æµ‹å€¼è¿ç»­
        futures.append(F_adj)

    futures = np.vstack(futures)
    pred  = futures.mean(axis=0)
    sigma = futures.std(axis=0, ddof=1)

    idx = pd.date_range(start=y.index[-1] + pd.Timedelta(minutes=1), periods=steps, freq="T")
    center = pd.Series(pred, index=idx)
    lower  = pd.Series(pred - Z_FIXED * sigma, index=idx)
    upper  = pd.Series(pred + Z_FIXED * sigma, index=idx)
    return center, lower, upper

# ============== é¡µé¢ & ä¾§æ è¡¨å•ï¼ˆä¸­æ–‡ï¼‰ ==============
st.set_page_config(page_title="æ°´åˆ€é¢„æµ‹çœ‹æ¿", layout="wide")
st.title("æ°´åˆ€é¢„æµ‹çœ‹æ¿")

# é¡¶éƒ¨æ“ä½œåŒºï¼šåˆ·æ–°æŒ‰é’®ï¼ˆåªæ›´æ–°ç¼“å­˜é”®ï¼Œå¿…è¦æ—¶æŠŠç»“æŸæ—¶é—´æ‹‰åˆ°å½“å‰ï¼‰
cTop1, cTop2, cTop3 = st.columns([1, 1, 6])
if cTop1.button("ğŸ”„ åˆ·æ–°æœ€æ–°å€¼", use_container_width=True):
    # æ›´æ–°ç»“æŸæ—¶é—´ä¸ºå½“å‰ï¼Œç¡®ä¿èƒ½å–åˆ°æœ€æ–°æ•°æ®ï¼ˆå¦‚æœç”¨æˆ·ä¹‹å‰é€‰çš„æ˜¯å†å²çª—å£ï¼‰
    now_sh = local_now()
    st.session_state["sel_date"] = now_sh.date()
    st.session_state["eh"] = now_sh.hour
    st.session_state["em"] = now_sh.minute
    # å¢åŠ ç¼“å­˜ç ´åå› å­ï¼Œå¼ºåˆ¶é‡æ–°æŠ“æ•°
    st.session_state["cache_buster"] = ss_get("cache_buster", 0) + 1
    st.rerun()

st.sidebar.header("å‚æ•°è®¾ç½®")

# ---- ä¼ æ„Ÿå™¨é€‰æ‹©ï¼ˆå¸¦ index å…œåº•ï¼‰----
options = list(SENSOR_MAP.values())
default_label = ss_get("sensor_label", options[0])
default_idx = options.index(default_label) if default_label in options else 0
sensor_label = st.sidebar.selectbox("ä¼ æ„Ÿå™¨", options, index=default_idx, key="sensor_label")
sensor_id = LABEL_TO_ID[sensor_label]

# ---- æ—¥æœŸ + æ—¶é—´ï¼ˆå°æ—¶/åˆ†é’Ÿæ‹†åˆ†ï¼‰----
sel_date = st.sidebar.date_input("æ—¥æœŸ", value=ss_get("sel_date", local_now().date()), key="sel_date")
hrs  = list(range(24))
mins = list(range(60))
c1, c2 = st.sidebar.columns(2)
sh = c1.selectbox("å¼€å§‹-å°æ—¶",   hrs, index=ss_get("sh", (local_now()-timedelta(hours=2)).hour),   key="sh")
sm = c2.selectbox("å¼€å§‹-åˆ†é’Ÿ",   mins, index=ss_get("sm", (local_now()-timedelta(hours=2)).minute), key="sm")
c3, c4 = st.sidebar.columns(2)
eh = c3.selectbox("ç»“æŸ-å°æ—¶",     hrs, index=ss_get("eh", local_now().hour),                        key="eh")
em = c4.selectbox("ç»“æŸ-åˆ†é’Ÿ",     mins, index=ss_get("em", local_now().minute),                     key="em")

# ---- é¢„æµ‹å‚æ•° ----
steps   = st.sidebar.number_input("æœªæ¥é¢„æµ‹åˆ†é’Ÿæ•°",       min_value=5,  max_value=240,
                                   value=ss_get("steps", 30),   step=5, key="steps")
pat_len = st.sidebar.number_input("ç›¸ä¼¼ç‰‡æ®µé•¿åº¦(åˆ†é’Ÿ)",   min_value=6,  max_value=120,
                                   value=ss_get("pat_len", 12), step=1, key="pat_len")
top_k   = st.sidebar.number_input("Top-K ç›¸ä¼¼ç‰‡æ®µæ•°",     min_value=1,  max_value=10,
                                   value=ss_get("top_k", 3),   step=1, key="top_k")
roll_w  = st.sidebar.number_input("æ»šåŠ¨å‡å€¼çª—å£(åˆ†é’Ÿ)",   min_value=3,  max_value=30,
                                   value=ss_get("roll_w", 7),  step=1, key="roll_w")

# "æ¢å¤é»˜è®¤"æŒ‰é’® + å ä½
cbtn1, cbtn2 = st.sidebar.columns(2)
if cbtn1.button("æ¢å¤é»˜è®¤", use_container_width=True):
    reset_to_defaults()
cbtn2.write("")  # å ä½ï¼Œä½¿å¸ƒå±€å¯¹é½

# ---- è¡¨å•æäº¤æŒ‰é’®ï¼šå¿…é¡»ç‚¹â€œå¼€å§‹é¢„æµ‹â€æ‰ä¼šæ‰§è¡Œ ----
with st.sidebar.form("params_form", clear_on_submit=False):
    submitted = st.form_submit_button("å¼€å§‹é¢„æµ‹", type="primary", use_container_width=True)

# ç»„è£…æ—¶é—´çª—å£ï¼ˆä¸Šæµ·æ—¶åŒº tz-awareï¼‰
start_sh = SH_TZ.localize(datetime.combine(st.session_state["sel_date"], time(st.session_state["sh"], st.session_state["sm"])))
end_sh   = SH_TZ.localize(datetime.combine(st.session_state["sel_date"], time(st.session_state["eh"], st.session_state["em"])))
if end_sh <= start_sh:
    end_sh = start_sh + timedelta(minutes=1)

# ============== ä¸»æµç¨‹ï¼ˆä»…åœ¨ submitted=True æ—¶è¿è¡Œï¼‰ ==============
if not submitted:
    st.info("è¯·åœ¨å·¦ä¾§è®¾ç½®å‚æ•°åç‚¹å‡» **å¼€å§‹é¢„æµ‹**ã€‚å¦‚éœ€ä»…æ›´æ–°æœ€æ–°å€¼ï¼Œè¯·ç‚¹å‡»é¡¶éƒ¨çš„ **åˆ·æ–°æœ€æ–°å€¼**ã€‚")
    st.stop()

with st.spinner("æ­£åœ¨æŠ“å–æ•°æ®å¹¶è®¡ç®—é¢„æµ‹..."):
    try:
        ts = fetch_minutely_last(sensor_id, start_sh, end_sh, ss_get("cache_buster", 0))
    except Exception as e:
        st.error(f"æ•°æ®è·å–å¤±è´¥ï¼š{e}")
        st.stop()

if ts.dropna().empty:
    st.warning("æ‰€é€‰æ—¶é—´èŒƒå›´å†…æ— æ•°æ®ï¼Œè¯·æ›´æ¢æ—¶é—´èŒƒå›´ã€‚")
    st.stop()

smoothed = ts.rolling(window=int(roll_w), min_periods=1).mean()

# é¢„æµ‹
holt_c, holt_lo, holt_up = holt_damped(ts, int(steps))
pat_c,  pat_lo,  pat_up  = pattern_match_fast(ts, int(steps), pat_len=int(pat_len), k=int(top_k))

# è½¬ç»˜å›¾ç´¢å¼•å¹¶é™é‡‡æ ·
ts_p, sm_p = tz_to_plot(ts), tz_to_plot(smoothed)
holt_c_p, holt_lo_p, holt_up_p = tz_to_plot(holt_c), tz_to_plot(holt_lo), tz_to_plot(holt_up)
pat_c_p,  pat_lo_p,  pat_up_p  = tz_to_plot(pat_c),  tz_to_plot(pat_lo),  tz_to_plot(pat_up)

ts_p   = downsample_for_plot(ts_p)
sm_p   = downsample_for_plot(sm_p)
holt_c_p, holt_lo_p, holt_up_p = map(downsample_for_plot, (holt_c_p, holt_lo_p, holt_up_p))
pat_c_p,  pat_lo_p,  pat_up_p  = map(downsample_for_plot, (pat_c_p,  pat_lo_p,  pat_up_p))

# ç”»å›¾ï¼ˆä¸­æ–‡ï¼‰
title = f"{sensor_label} â€” {start_sh.strftime('%Y-%m-%d %H:%M')} ~ {end_sh.strftime('%Y-%m-%d %H:%M')}"
fig, ax = plt.subplots(figsize=(11, 5))

ax.plot(ts_p.index, ts_p.values, label="å®é™…å€¼", lw=1.1, alpha=0.6)
ax.plot(sm_p.index, sm_p.values, label="å¹³æ»‘", lw=1.6)

ax.plot(holt_c_p.index, holt_c_p.values, "--", label="Holt(é˜»å°¼)")
ax.fill_between(holt_c_p.index, holt_lo_p.values, holt_up_p.values, alpha=0.12, label="Holt ç½®ä¿¡åŒºé—´")

ax.plot(pat_c_p.index, pat_c_p.values, "--", label=f"å†å²ç›¸ä¼¼æ®µ (Top-{int(top_k)})")
ax.fill_between(pat_c_p.index, pat_lo_p.values, pat_up_p.values, alpha=0.12, label="ç›¸ä¼¼æ®µ ç½®ä¿¡åŒºé—´")

ax.set_title(title); ax.set_xlabel("æ—¶é—´"); ax.set_ylabel("æ¸©åº¦ (Â°C)")
ax.grid(True, alpha=0.3); ax.legend(loc="best")
ax.xaxis.set_major_locator(mdates.AutoDateLocator())
ax.xaxis.set_major_formatter(mdates.DateFormatter("%H:%M"))
st.pyplot(fig, clear_figure=True)

# å¿«é€ŸæŒ‡æ ‡ï¼šæœ€æ–°æ¸©åº¦ + æ•…éšœç‡
latest_series = tz_to_plot(ts).dropna()
latest_idx = latest_series.index.max() if not latest_series.empty else None
if latest_idx is not None:
    latest_temp = float(ts.dropna().iloc[-1])
    rate = fault_rate_from_temp(latest_temp)
    cA, cB, cC = st.columns([1, 2, 5])
    cA.metric("æœ€æ–°æ¸©åº¦ (Â°C)", f"{latest_temp:.2f}")
    cB.markdown(f"**æ—¶é—´ï¼š** {latest_idx.strftime('%Y-%m-%d %H:%M')}")
    if not np.isnan(rate):
        cC.metric("æ•…éšœç‡", f"{rate*100:.0f}%")
else:
    st.info("å½“å‰çª—å£æš‚æ— å¯ç”¨æœ€æ–°å€¼ã€‚")
