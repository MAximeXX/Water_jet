# app.py â€” Waterjet Forecastï¼ˆå…¨ä¸­æ–‡ + è‡ªåŠ¨é¢„æµ‹ + åˆ·æ–° + æ•…éšœç‡ï¼‰
# ------------------------------------------------
# - DB ç«¯ 1 åˆ†é’Ÿèšåˆï¼šé™ä½ä¼ è¾“é‡ã€åŠ é€Ÿ
# - ä¸¤ä¸ªé¢„æµ‹æ–¹æ³•ï¼šHoltï¼ˆé˜»å°¼ï¼‰ + å†å²ç›¸ä¼¼æ®µï¼ˆTop-Kï¼‰
# - è¿›å…¥é¡µé¢å³è‡ªåŠ¨æŠ“æ•°+é¢„æµ‹ï¼›ä¾§æ ä»å¯è°ƒå‚æ•°ï¼›æä¾›â€œåˆ·æ–°æ•°æ®â€æŒ‰é’®
# - Latest Temp åæ–°å¢â€œæ•…éšœç‡â€æ˜¾ç¤ºï¼šè§ compute_failure_rate()

import os
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib import font_manager as fm
import requests

from datetime import datetime, time, timedelta, timezone
import pytz

FONT_PATH = "fonts\NotoSansSC-Regular.otf"  # ä½ çš„å­—ä½“ç›¸å¯¹è·¯å¾„

def setup_chinese_font():
    try:
        if os.path.exists(FONT_PATH):
            fm.fontManager.addfont(FONT_PATH)
            font_prop = fm.FontProperties(fname=FONT_PATH)
            # å°†å…¨å±€å­—ä½“è®¾ä¸ºè¯¥ä¸­æ–‡å­—ä½“
            plt.rcParams["font.family"] = font_prop.get_name()
        else:
            # å…œåº•ï¼šå¦‚æœç¼ºæ–‡ä»¶ï¼Œå°½é‡ä½¿ç”¨ç³»ç»Ÿé‡Œå¸¸è§çš„ä¸­æ–‡å­—ä½“å
            plt.rcParams["font.sans-serif"] = [
                "Noto Sans SC", "Source Han Sans CN", "Microsoft YaHei",
                "PingFang SC", "Heiti SC", "SimHei", "Arial Unicode MS", "DejaVu Sans"
            ]
        # è®©è´Ÿå·æ­£å¸¸æ˜¾ç¤ºï¼ˆä¸è¢«å½“ä½œæ–¹å—ï¼‰
        plt.rcParams["axes.unicode_minus"] = False
    except Exception as e:
        # å‡ºé”™ä¹Ÿä¸è¦å½±å“ä¸»æµç¨‹
        print("Chinese font setup failed:", e)

setup_chinese_font()

# ============== åŸºç¡€é…ç½® ==============
API_URL      = "http://61.177.143.140:8086/query"
DB_NAME      = "DataDB"
MEASUREMENT  = "working_set"
READ_TIMEOUT = (10, 90)
SH_TZ        = pytz.timezone("Asia/Shanghai")
Z_FIXED      = 1.96                   # 95% ç½®ä¿¡åŒºé—´ç³»æ•°
MAX_PLOT_POINTS = 2500                # ç»˜å›¾é™é‡‡æ ·ä¸Šé™ï¼ˆä¸å½±å“é¢„æµ‹ï¼Œä»…å½±å“æ˜¾ç¤ºï¼‰

# ä¼ æ„Ÿå™¨æ˜ å°„ï¼šid -> å¯è¯»åç§°ï¼ˆå¯è‡ªè¡Œæ‰©å±•/æ›¿æ¢ï¼‰
SENSOR_MAP = {
    "wxa01sd01.calculate.sdjsd0011": "æ°´æ³µæ¸©åº¦1",
    "wxa01sd01.calculate.sdjsd0012": "æ°´æ³µæ¸©åº¦2",
}
LABEL_TO_ID = {v: k for k, v in SENSOR_MAP.items()}

# å¤ç”¨è¿æ¥
SESSION = requests.Session()

# ============== å·¥å…·å‡½æ•° ==============
def local_now():
    """è·å–ä¸Šæµ·æœ¬åœ°å½“å‰æ—¶é—´ï¼ˆå»ç§’ï¼‰ã€‚"""
    return datetime.now(SH_TZ).replace(second=0, microsecond=0)

def tz_to_plot(s: pd.Series) -> pd.Series:
    """æŠŠç´¢å¼•è½¬æˆä¸Šæµ·æ—¶åŒºä¸” naiveï¼ŒMatplotlib ç”»å›¾æ›´ç¨³ã€‚"""
    s = s.copy()
    if hasattr(s.index, "tz"):
        s.index = s.index.tz_convert(SH_TZ).tz_localize(None)
    return s

def downsample_for_plot(s: pd.Series, max_pts=MAX_PLOT_POINTS) -> pd.Series:
    """ç»˜å›¾ç”¨è½»åº¦ä¸‹é‡‡æ ·ï¼ˆä»…å½±å“å±•ç¤ºï¼Œä¸å½±å“è¿ç®—ï¼‰ã€‚"""
    if s.empty or len(s) <= max_pts:
        return s
    step = max(1, len(s) // max_pts)
    return s.iloc[::step]

def compute_failure_rate(temp: float) -> float:
    """
    æ•…éšœç‡å®šä¹‰ï¼š
      - æ¸©åº¦ >= 45â„ƒ => 100%
      - æ¸©åº¦ <= 25â„ƒ => 0%
      - å…¶ä½™ï¼šçº¿æ€§æ’å€¼ (temp-25)/(45-25)*100
    """
    if temp >= 45:
        return 100.0
    if temp <= 25:
        return 0.0
    return (temp - 25.0) / (45.0 - 25.0) * 100.0

# ============== é»˜è®¤å‚æ•° ==============
def compute_defaults():
    """æ„é€ ä¸€å¥—â€œå½“å‰æ—¶é—´å‘å‰ 2 å°æ—¶â€çš„é»˜è®¤å‚æ•°"""
    now_sh   = local_now()
    start_sh = now_sh - timedelta(hours=2)
    return {
        "sensor_label": list(SENSOR_MAP.values())[0],
        "sel_date": now_sh.date(),
        "sh": start_sh.hour, "sm": start_sh.minute,   # start hour/minute
        "eh": now_sh.hour,   "em": now_sh.minute,     # end   hour/minute
        "steps": 30, "pat_len": 12, "top_k": 3, "roll_w": 7,
        "cache_buster": 0,   # ç”¨äºå¼ºåˆ¶åˆ·æ–°ç¼“å­˜çš„é”®
    }

# âœ… åœ¨ä»»ä½• UI æ§ä»¶ä¹‹å‰ï¼Œç¡®ä¿ session_state å®Œæ•´åˆå§‹åŒ–
if "inited" not in st.session_state:
    st.session_state.update(compute_defaults())
    st.session_state["inited"] = True

def reset_to_defaults():
    st.session_state.update(compute_defaults())
    st.rerun()

def ss_get(key, default):
    """å®‰å…¨è¯»å– session_stateï¼ˆå…œåº•ï¼‰ã€‚"""
    return st.session_state[key] if key in st.session_state else default

# ============== DB ä¾§ 1 åˆ†é’ŸèšåˆæŠ“å– ==============
@st.cache_data(ttl=120)
def fetch_minutely_last(sensor_id: str, start_sh: datetime, end_sh: datetime, buster: int) -> pd.Series:
    """
    InfluxQLï¼ˆå¯¹ 1.8 OSS å‹å¥½ï¼‰ï¼š
      - ç”¨ RFC3339 UTC æ—¶é—´æ–‡æœ¬ï¼ˆç¨³å®šï¼‰
      - åœ¨ DB ç«¯åš 1 åˆ†é’Ÿèšåˆï¼šlast(val)
      - å®¢æˆ·ç«¯å†è½¬å›ä¸Šæµ·æ—¶åŒº
    è¯´æ˜ï¼šbuster ä»…ç”¨äºå½±å“ç¼“å­˜é”®ï¼Œå®ç°â€œåˆ·æ–°æ•°æ®â€ã€‚
    """
    start_utc = start_sh.astimezone(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
    end_utc   = end_sh.astimezone(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")

    q = (
        f'SELECT last("val") AS v FROM "{MEASUREMENT}" '
        f"WHERE time >= '{start_utc}' AND time <= '{end_utc}' "
        f"AND \"id\" = '{sensor_id}' "
        f"GROUP BY time(1m) fill(none)"
    )
    r = SESSION.get(API_URL, params={"db": DB_NAME, "q": q, "epoch": "ms"}, timeout=READ_TIMEOUT)
    r.raise_for_status()
    payload = r.json()
    series = payload.get("results", [{}])[0].get("series", [])
    if not series:
        return pd.Series(dtype=float)

    s0 = series[0]
    df = pd.DataFrame(s0["values"], columns=s0["columns"])  # columns: time, v
    if df.empty or "time" not in df or "v" not in df:
        return pd.Series(dtype=float)

    df["time"] = pd.to_datetime(df["time"], unit="ms", utc=True).dt.tz_convert(SH_TZ)
    df = df.dropna(subset=["v"])
    s = df.set_index("time")["v"].astype(float).sort_index()

    # å¯¹é½å®Œæ•´åˆ†é’Ÿç´¢å¼•ï¼ˆç¼ºå¤±åˆ†é’Ÿä¿ç•™ NaNï¼‰
    full_idx = pd.date_range(start=start_sh, end=end_sh, freq="T", tz=SH_TZ)
    return s.reindex(full_idx)

# ============== é¢„æµ‹æ–¹æ³• ==============
def ci_from_sigma(center: pd.Series, sigma: float, hist_len: int, z: float = Z_FIXED):
    """åŸºäºæ®‹å·®æ ‡å‡†å·®çš„ç®€åŒ–ç½®ä¿¡åŒºé—´ï¼ˆæ­¥é•¿è¶Šè¿œç•¥æ”¾å®½ï¼‰ã€‚"""
    h = np.arange(1, len(center) + 1)
    widen = np.sqrt(1.0 + h / max(5, hist_len))
    return center - z * sigma * widen, center + z * sigma * widen

@st.cache_data(ttl=120, show_spinner=False)
def holt_damped(y: pd.Series, steps: int, buster: int):
    """Holt é˜»å°¼è¶‹åŠ¿ï¼ˆstatsmodelsï¼›å¤±è´¥æ—¶å›é€€ä¸ºæŒä¹…åŒ–ï¼‰ã€‚"""
    y = y.dropna().sort_index()
    if y.empty or steps <= 0:
        return y.iloc[-0:0], y.iloc[-0:0], y.iloc[-0:0]
    try:
        from statsmodels.tsa.holtwinters import ExponentialSmoothing
        model = ExponentialSmoothing(y, trend="add", damped_trend=True, seasonal=None)
        fit = model.fit(optimized=True)
        pred = fit.forecast(steps)
        pred.index = pd.date_range(start=y.index[-1] + pd.Timedelta(minutes=1), periods=steps, freq="T")
        resid = (y - fit.fittedvalues.reindex(y.index)).dropna()
        sigma = float(resid.std(ddof=1)) if len(resid) > 3 else 0.0
        lo, up = ci_from_sigma(pred, sigma, len(y), Z_FIXED)
        return pred, lo, up
    except Exception:
        last = float(y.iloc[-1])
        idx = pd.date_range(start=y.index[-1] + pd.Timedelta(minutes=1), periods=steps, freq="T")
        base = pd.Series([last] * steps, index=idx)
        return base, base, base

@st.cache_data(ttl=120, show_spinner=False)
def pattern_match_fast(y: pd.Series, steps: int, pat_len: int, k: int, buster: int):
    """çŸ¢é‡åŒ– Top-K å†å²ç›¸ä¼¼æ®µåŒ¹é…ï¼Œå½¢çŠ¶é…å‡†åé›†æˆã€‚"""
    y = y.dropna().sort_index()
    arr = y.values.astype(float)
    n = len(arr); need = pat_len + steps
    if steps <= 0 or n <= need:
        idx = pd.date_range(start=y.index[-1] + pd.Timedelta(minutes=1), periods=steps, freq="T")
        base = pd.Series([float(arr[-1])] * steps, index=idx)
        return base, base, base

    P = arr[-pat_len:]
    stride = arr.strides[0]
    m = n - need + 1
    windows = np.lib.stride_tricks.as_strided(arr, shape=(m, pat_len), strides=(stride, stride))

    win_mu = windows.mean(axis=1, keepdims=True)
    win_sd = windows.std(axis=1, keepdims=True); win_sd[win_sd == 0] = 1.0
    win_z  = (windows - win_mu) / win_sd
    Pz = (P - P.mean()) / (P.std() or 1.0)

    # è¿‘ä¼¼â€œç›¸å…³ç³»æ•°â€çš„ç›¸ä¼¼åº¦
    scores = (win_z * Pz).sum(axis=1) / pat_len
    k = max(1, min(k, m))
    top_idx = np.argpartition(-scores, kth=k-1)[:k]

    futures = []
    for sidx in top_idx:
        F = arr[sidx + pat_len : sidx + pat_len + steps]
        Fz = (F - F.mean()) / (F.std() or 1.0)
        F_adj = Fz * (P.std() or 1.0) + P.mean()
        F_adj += (P[-1] - F_adj[0])           # ä¸æœ€åä¸€ä¸ªè§‚æµ‹å€¼è¿ç»­
        futures.append(F_adj)

    futures = np.vstack(futures)
    pred  = futures.mean(axis=0)
    sigma = futures.std(axis=0, ddof=1)

    idx = pd.date_range(start=y.index[-1] + pd.Timedelta(minutes=1), periods=steps, freq="T")
    center = pd.Series(pred, index=idx)
    lower  = pd.Series(pred - Z_FIXED * sigma, index=idx)
    upper  = pd.Series(pred + Z_FIXED * sigma, index=idx)
    return center, lower, upper

# ============== é¡µé¢ & ä¾§æ è¡¨å•ï¼ˆä¸­æ–‡åŒ–ï¼‰ ==============
st.set_page_config(page_title="æ°´åˆ€é¢„æµ‹çœ‹æ¿", layout="wide")
st.title("æ°´åˆ€é¢„æµ‹çœ‹æ¿")

# é¡¶éƒ¨æ“ä½œåŒºï¼šåˆ·æ–° & æ¢å¤é»˜è®¤
col_top_left, col_top_right = st.columns([1,1])
with col_top_left:
    if st.button("ğŸ”„ åˆ·æ–°æ•°æ®", use_container_width=True):
        st.session_state["cache_buster"] = ss_get("cache_buster", 0) + 1
        st.rerun()
with col_top_right:
    if st.button("ğŸ§¹ æ¢å¤é»˜è®¤å‚æ•°", use_container_width=True):
        reset_to_defaults()

st.sidebar.header("å‚æ•°è®¾ç½®")

# ---- ä¼ æ„Ÿå™¨é€‰æ‹© ----
options = list(SENSOR_MAP.values())
default_label = ss_get("sensor_label", options[0])
default_idx = options.index(default_label) if default_label in options else 0
sensor_label = st.sidebar.selectbox("ä¼ æ„Ÿå™¨", options, index=default_idx, key="sensor_label")
sensor_id = LABEL_TO_ID[sensor_label]

# ---- æ—¥æœŸ + æ—¶é—´ï¼ˆå°æ—¶/åˆ†é’Ÿæ‹†åˆ†ï¼‰----
sel_date = st.sidebar.date_input("é€‰æ‹©æ—¥æœŸ", value=ss_get("sel_date", local_now().date()), key="sel_date")
hrs  = list(range(24))
mins = list(range(60))
c1, c2 = st.sidebar.columns(2)
sh = c1.selectbox("å¼€å§‹å°æ—¶",   hrs, index=ss_get("sh", (local_now()-timedelta(hours=2)).hour),   key="sh")
sm = c2.selectbox("å¼€å§‹åˆ†é’Ÿ",   mins, index=ss_get("sm", (local_now()-timedelta(hours=2)).minute), key="sm")
c3, c4 = st.sidebar.columns(2)
eh = c3.selectbox("ç»“æŸå°æ—¶",   hrs, index=ss_get("eh", local_now().hour),                        key="eh")
em = c4.selectbox("ç»“æŸåˆ†é’Ÿ",   mins, index=ss_get("em", local_now().minute),                     key="em")

# ---- é¢„æµ‹å‚æ•° ----
steps   = st.sidebar.number_input("é¢„æµ‹æœªæ¥åˆ†é’Ÿæ•°",     min_value=5,  max_value=240,
                                   value=ss_get("steps", 30),   step=5, key="steps")
pat_len = st.sidebar.number_input("ç›¸ä¼¼ç‰‡æ®µé•¿åº¦(åˆ†é’Ÿ)", min_value=6,  max_value=120,
                                   value=ss_get("pat_len", 12), step=1, key="pat_len")
top_k   = st.sidebar.number_input("Top-K ç›¸ä¼¼ç‰‡æ®µæ•°",   min_value=1,  max_value=10,
                                   value=ss_get("top_k", 3),   step=1, key="top_k")
roll_w  = st.sidebar.number_input("æ»šåŠ¨å¹³æ»‘çª—å£(åˆ†é’Ÿ)", min_value=3,  max_value=30,
                                   value=ss_get("roll_w", 7),  step=1, key="roll_w")

# ï¼ˆå¯é€‰ï¼‰ä¿ç•™â€œå¼€å§‹é¢„æµ‹â€æŒ‰é’®ï¼Œä½†ä¸å†ä½œä¸ºå¼ºåˆ¶é—¨æ§›ï¼›ç‚¹å‡»å¯ä½œä¸ºä¸€æ¬¡æ˜¾å¼åˆ·æ–°
with st.sidebar.form("params_form", clear_on_submit=False):
    submitted = st.form_submit_button("å¼€å§‹é¢„æµ‹", type="primary", use_container_width=True)
if submitted:
    st.session_state["cache_buster"] = ss_get("cache_buster", 0) + 1
    st.rerun()

# ç»„è£…æ—¶é—´çª—å£ï¼ˆä¸Šæµ·æ—¶åŒº tz-awareï¼‰
start_sh = SH_TZ.localize(datetime.combine(st.session_state["sel_date"], time(st.session_state["sh"], st.session_state["sm"])))
end_sh   = SH_TZ.localize(datetime.combine(st.session_state["sel_date"], time(st.session_state["eh"], st.session_state["em"])))
if end_sh <= start_sh:
    end_sh = start_sh + timedelta(minutes=1)

# ============== ä¸»æµç¨‹ï¼ˆè‡ªåŠ¨æ‰§è¡Œï¼‰ ==============
with st.spinner("æ­£åœ¨è·å–æ•°æ®å¹¶è¿›è¡Œé¢„æµ‹..."):
    try:
        ts = fetch_minutely_last(sensor_id, start_sh, end_sh, ss_get("cache_buster", 0))
    except Exception as e:
        st.error(f"æ•°æ®æŠ“å–å¤±è´¥ï¼š{e}")
        st.stop()

if ts.dropna().empty:
    st.warning("è¯¥æ—¶é—´æ®µæ²¡æœ‰æ•°æ®ï¼Œè¯·è°ƒæ•´æ—¶é—´èŒƒå›´ã€‚")
    st.stop()

# å¹³æ»‘
smoothed = ts.rolling(window=int(roll_w), min_periods=1).mean()

# é¢„æµ‹ï¼ˆä¸¤ç§ï¼‰
holt_c, holt_lo, holt_up = holt_damped(ts, int(steps), ss_get("cache_buster", 0))
pat_c,  pat_lo,  pat_up  = pattern_match_fast(ts, int(steps), pat_len=int(pat_len), k=int(top_k), buster=ss_get("cache_buster", 0))

# è½¬ç»˜å›¾ç´¢å¼•å¹¶é™é‡‡æ ·
ts_p, sm_p = tz_to_plot(ts), tz_to_plot(smoothed)
holt_c_p, holt_lo_p, holt_up_p = tz_to_plot(holt_c), tz_to_plot(holt_lo), tz_to_plot(holt_up)
pat_c_p,  pat_lo_p,  pat_up_p  = tz_to_plot(pat_c),  tz_to_plot(pat_lo),  tz_to_plot(pat_up)

ts_p   = downsample_for_plot(ts_p)
sm_p   = downsample_for_plot(sm_p)
holt_c_p, holt_lo_p, holt_up_p = map(downsample_for_plot, (holt_c_p, holt_lo_p, holt_up_p))
pat_c_p,  pat_lo_p,  pat_up_p  = map(downsample_for_plot, (pat_c_p,  pat_lo_p,  pat_up_p))

# ç”»å›¾ï¼ˆä¸­æ–‡å›¾ä¾‹ï¼‰
title = f"{sensor_label} â€” {start_sh.strftime('%Y-%m-%d %H:%M')} ~ {end_sh.strftime('%Y-%m-%d %H:%M')}"
fig, ax = plt.subplots(figsize=(11, 5))

ax.plot(ts_p.index, ts_p.values, label="å®é™…æ¸©åº¦", lw=1.1, alpha=0.6)
ax.plot(sm_p.index, sm_p.values, label="å¹³æ»‘æ¸©åº¦", lw=1.6)

ax.plot(holt_c_p.index, holt_c_p.values, "--", label="Holt(é˜»å°¼)é¢„æµ‹")
ax.fill_between(holt_c_p.index, holt_lo_p.values, holt_up_p.values, alpha=0.12, label="Holt ç½®ä¿¡åŒºé—´")

ax.plot(pat_c_p.index, pat_c_p.values, "--", label=f"å†å²ç›¸ä¼¼æ®µé¢„æµ‹(Top-{int(top_k)})")
ax.fill_between(pat_c_p.index, pat_lo_p.values, pat_up_p.values, alpha=0.12, label="ç›¸ä¼¼æ®µ ç½®ä¿¡åŒºé—´")

ax.set_title(title); ax.set_xlabel("æ—¶é—´"); ax.set_ylabel("æ¸©åº¦ (Â°C)")
ax.grid(True, alpha=0.3); ax.legend(loc="best")
ax.xaxis.set_major_locator(mdates.AutoDateLocator())
ax.xaxis.set_major_formatter(mdates.DateFormatter("%H:%M"))
st.pyplot(fig, clear_figure=True)

# å¿«é€ŸæŒ‡æ ‡ï¼šLatest Temp & æ•…éšœç‡
latest_idx = tz_to_plot(ts).dropna().index.max()
if pd.notna(latest_idx):
    latest_temp = float(ts.dropna().iloc[-1])
    failure_rate = compute_failure_rate(latest_temp)
    cA, cB, cC = st.columns([1,1,2])
    cA.metric("å®æ—¶æ¸©åº¦ (Â°C)", f"{latest_temp:.2f}")
    cB.metric("æ•…éšœç‡", f"{failure_rate:.0f}%")
    cC.write(f"æ—¶é—´ï¼š{latest_idx.strftime('%Y-%m-%d %H:%M')}ï¼ˆç‚¹å‡»ä¸Šæ–¹â€œåˆ·æ–°æ•°æ®â€å¯å³æ—¶æ›´æ–°ï¼‰")
